<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-09-17 Mon 22:56 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>DoorDash Data Science Project</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Qike Max Li" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../styles/bigblow/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../styles/bigblow/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="../styles/bigblow/css/hideshow.css"/>
<script type="text/javascript" src="../styles/bigblow/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/bigblow.js"></script>
<script type="text/javascript" src="../styles/bigblow/js/hideshow.js"></script>
<script type="text/javascript" src="../styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">DoorDash Data Science Project</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgf7d5388">1. A few thoughts</a>
<ul>
<li><a href="#org141d84d">1.1. Overview</a>
<ul>
<li><a href="#org07c99b2">1.1.1. Objectives</a></li>
<li><a href="#org3af2aa8">1.1.2. Datasets</a></li>
<li><a href="#orgb9a29a5">1.1.3. My approach</a></li>
</ul>
</li>
<li><a href="#orge041986">1.2. Challenges</a>
<ul>
<li><a href="#org00539e5">1.2.1. Missing values</a></li>
<li><a href="#org4eac27f">1.2.2. Feature engineering</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb119980">2. EDA</a>
<ul>
<li><a href="#org10da7c1">2.1. Add some features</a>
<ul>
<li><a href="#orga9a6933">2.1.1. Extract day of week and hour of day</a></li>
<li><a href="#org45b6990">2.1.2. Investigate the average market features for each day of a week and each hour of a day</a></li>
<li><a href="#orgd812eda">2.1.3. Hour of day</a></li>
</ul>
</li>
<li><a href="#org88e72b8">2.2. Missing values</a>
<ul>
<li><a href="#orgaed3c97">2.2.1. Count the number of missing values for each column</a></li>
<li><a href="#org5564508">2.2.2. Impute the missing values for some columns</a></li>
<li><a href="#org9021131">2.2.3. Treat the <code>NaN</code> as an extra level of the categorical variable</a></li>
<li><a href="#orgb4e7003">2.2.4. Remove some data points</a></li>
</ul>
</li>
<li><a href="#org4b51796">2.3. Compute the duration from orders created to orders delivered</a></li>
</ul>
</li>
<li><a href="#org608c609">3. Training</a>
<ul>
<li><a href="#org5ca7a10">3.1. Automatic Machine Learnig (AutoML)</a></li>
<li><a href="#orgc1bfa1c">3.2. Mixed effects model</a></li>
</ul>
</li>
<li><a href="#org2923cea">4. Prediction</a>
<ul>
<li><a href="#org9d349d5">4.1. Script for model serving</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgf7d5388" class="outline-2">
<h2 id="orgf7d5388"><span class="section-number-2">1</span> A few thoughts</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org141d84d" class="outline-3">
<h3 id="org141d84d"><span class="section-number-3">1.1</span> Overview</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org07c99b2" class="outline-4">
<h4 id="org07c99b2"><span class="section-number-4">1.1.1</span> Objectives</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
Given a few categorical and numerical variables, predict the delivery time.
</p>
</div>
</div>
<div id="outline-container-org3af2aa8" class="outline-4">
<h4 id="org3af2aa8"><span class="section-number-4">1.1.2</span> Datasets</h4>
<div class="outline-text-4" id="text-1-1-2">
<ul class="org-ul">
<li>historical data</li>
<li>test data</li>
</ul>
</div>
</div>
<div id="outline-container-orgb9a29a5" class="outline-4">
<h4 id="orgb9a29a5"><span class="section-number-4">1.1.3</span> My approach</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
Due to time constraints, in this exercise, I don't strive for the best performing model but rather to demonstrate how I approach a data science problem. In other words, no attempts were made in carefully tuning the models. Heavy model tuning often lead to only incremental increase of model accuracy. Whereas, substantial accuracy gain are often resulted from better understanding of the problem, identifying the right features to collect, and designing models to represent the special structure/characteristics in data.  
</p>
</div>
</div>
</div>
<div id="outline-container-orge041986" class="outline-3">
<h3 id="orge041986"><span class="section-number-3">1.2</span> Challenges</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org00539e5" class="outline-4">
<h4 id="org00539e5"><span class="section-number-4">1.2.1</span> Missing values</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
In the historical dataset, some variables have missing values. Note, throughout this report I use variables and features interchangeably. 
</p>
</div>
<ol class="org-ol">
<li><a id="org6292264"></a><code>total_onshift_dashers</code>, <code>total_busy_dashers</code>, and <code>total_outstanding_orders</code><br />
<div class="outline-text-5" id="text-1-2-1-1">
<p>
These variables represent market features. Since the market feature of the same time, i.e. the same hour of the same day of week, should be reasonably consistent. To impute the missing values, I took the average of these variables from the same time.
</p>
</div>
</li>
<li><a id="orgbbad6ed"></a><code>estimated_store_to_consumer_driving_duration</code><br />
<div class="outline-text-5" id="text-1-2-1-2">
<p>
This is the estimated travel time between store and consumer. Stores located at areas with heavy traffic may tend to have longer driving duration time, and vice versa. Therefore, I used the average of driving duration time of a store to fill in the missing driving duration times of the same store. Note, this may not be a good strategy to fill in the missing values since the driving time should also depend on the distance from a customer to a store. To determine the approach of engineering this feature, model performances should be compared between with and without imputing this variable.
</p>
</div>
</li>
<li><a id="org717c3da"></a><code>store_primary_category</code><br />
<div class="outline-text-5" id="text-1-2-1-3">
<p>
A store often offers one type of cuisine. Therefore, for each store, I take its most frequent category to fill in the missing values.
</p>
</div>
</li>
<li><a id="org15ff604"></a><code>market_id</code> and <code>order_protocol</code><br />
<div class="outline-text-5" id="text-1-2-1-4">
<p>
Instead of imputing the missing values for these two variables, I chose to treat the missing values as an extra level of the categorical variables since the their possible values cannot be inferred from the other variables. 
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org4eac27f" class="outline-4">
<h4 id="org4eac27f"><span class="section-number-4">1.2.2</span> Feature engineering</h4>
<div class="outline-text-4" id="text-1-2-2">
</div>
<ol class="org-ol">
<li><a id="orgf964093"></a>The cyclic nature of the feature <code>hour</code><br />
<div class="outline-text-5" id="text-1-2-2-1">
<p>
Hour of day is an ordinal cyclic variables. It is inappropriate to treat this variable as numeric or ordinal.
</p>

<p>
Delivery time heavily depends on the hour of day, and <code>hour</code> should definitely be included as a feature. It is not ideal to treat hour as a numerical variable since delivery time at 1am should be similar to that at midnight (hour=24). If we treat <code>hour</code> as a numerical variable, we implicitly assume the delivery time at 1am should be much similar to the delivery time at 2am than to the delivery time at midnight.
To take care of cyclicity, I did the following trigonometric transformation
</p>

\begin{eqnarray*}
x &=& \sin(2\pi\cdot hour/24)\\
y &=& \cos(2\pi\cdot hour/24)
\end{eqnarray*}

<p>
After the transformation, the distance between 1am and 24:00 and the distance between 1am and 2am are the same. Hence, I replaced the variable <code>hour</code> by <code>x-hour</code> and <code>y-hour</code>.  Note, even with deep learning, which doesn't require intensive feature engineering, these features are not likely to automatically emerge.
</p>


<div class="figure">
<p><img src="./Figures/fig-hour.png" alt="fig-hour.png" />
</p>
</div>
</div>
</li>

<li><a id="org16a9551"></a>Linear vs non-linear; additive vs. interactive<br />
<div class="outline-text-5" id="text-1-2-2-2">
<p>
Linear assumption is inappropriate since the delivery time never linearly increase as the other variables (e.g. <code>week of day</code>) increase.
</p>

<p>
The additive assumption is also inappropriate since interactive effects, such as <code>week of day</code> and <code>hour</code>, clearly exist. 
</p>
</div>
</li>

<li><a id="org0f99411"></a>Random effects<br />
<div class="outline-text-5" id="text-1-2-2-3">
<p>
Random effects models — also known as hierarchical models — allow us to ascribe distinct behaviors to different "clusters" of observations, e.g. markets (<code>market_id</code>) may each act in a unique way. Furthermore, these models allow us to infer these tendencies in a collaborative fashion: while each market/cluster is assumed to behave differently, their parameters can be learned by heeding to the behavior of the population at large.
</p>

<p>
Linear mixed effects model is a widely used model to incorporate the random effects. However, since this model is a linear model, we need to manually engineer the features to incorporate the non-linearity and interactions between features.  
</p>

<p>
Neural networks are powerful function approximators and seem particularly suitable in this case to avoid the explicit feature engineering. Therefore, I also explored random effects models with deep neural network basis functions. 
</p>

<p>
To my knowledge, there are no available algorithms to model the random effects while approximating basis functions by neural networks. Fortunately, Bayesian probabilistic models provide a nimble and expressive framework. <a href="http://www.edwardlib.org">Edward</a> is a probabilistic programming library that enables easy implementation of Bayesian probabilistic/generative models. Moreover, Edward uses TensorFlow as backend and variational inference as the inference tool, which allows the implemented algorithms to scale to massive data. Given the time constraints, my initial attempt is only exploratory, and I didn't end up using this model for model serving.
</p>
</div>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgb119980" class="outline-2">
<h2 id="orgb119980"><span class="section-number-2">2</span> EDA</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org10da7c1" class="outline-3">
<h3 id="org10da7c1"><span class="section-number-3">2.1</span> Add some features</h3>
<div class="outline-text-3" id="text-2-1">
<p>
The delivery time may depend on which day of week and which hour of day. Therefore, I extracted week of day and hour of day from the variable <code>created_at</code>
</p>
</div>

<div id="outline-container-orga9a6933" class="outline-4">
<h4 id="orga9a6933"><span class="section-number-4">2.1.1</span> Extract day of week and hour of day</h4>
<div class="outline-text-4" id="text-2-1-1">
<div class="org-src-container">
<pre class="src src-ipython">import math
from datetime import datetime

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

%matplotlib inline
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">Train = pd.read_csv('../../Data Science/historical_data.csv')
Train.actual_delivery_time = \
    pd.to_datetime(Train.actual_delivery_time)
Train.created_at = pd.to_datetime(Train.created_at)
Train['weekday'] = Train.created_at.map(lambda x: x.weekday())
Train['hour'] = Train.created_at.map(lambda x: x.hour)
</pre>
</div>
</div>
</div>

<div id="outline-container-org45b6990" class="outline-4">
<h4 id="org45b6990"><span class="section-number-4">2.1.2</span> Investigate the average market features for each day of a week and each hour of a day</h4>
<div class="outline-text-4" id="text-2-1-2">
</div>
<ol class="org-ol">
<li><a id="org1a9dc1c"></a>Market feature vary substantially from day to day<br />
<div class="outline-text-5" id="text-2-1-2-1">
<div class="org-src-container">
<pre class="src src-ipython">grouped_mean_day = Train.groupby('weekday').agg({
    'total_onshift_dashers':
    np.sum,
    'total_busy_dashers':
    np.sum,
    'total_outstanding_orders':
    np.sum
})

# create plot
fig, ax = plt.subplots()
index = grouped_mean_day.index.values
bar_width = 0.25
opacity = 0.8

rects1 = plt.bar(
    index,
    grouped_mean_day.total_busy_dashers,
    bar_width,
    alpha=opacity,
    color='b',
    label='# busy_dashers')

rects2 = plt.bar(
    index + bar_width,
    grouped_mean_day.total_onshift_dashers,
    bar_width,
    alpha=opacity,
    color='g',
    label='# onshift_dashers')

rects3 = plt.bar(
    index + 2 * bar_width,
    grouped_mean_day.total_outstanding_orders,
    bar_width,
    alpha=opacity,
    color='r',
    label='# outstanding_orders')

plt.xlabel('Day of Week')
plt.ylabel('Market Features')
plt.title('Market Features by day')
plt.xticks(index + bar_width,
           ('Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'))
plt.legend()
</pre>
</div>

<pre class="example">
&lt;matplotlib.legend.Legend at 0x1105cc350&gt;

</pre>

<div class="figure">
<p><img src="./obipy-resources/57942XTf.png" alt="57942XTf.png" />
</p>
</div>
</div>
</li>

<li><a id="org03449a6"></a>Market feature vary substantially from hour to hour<br />
<div class="outline-text-5" id="text-2-1-2-2">
<p>
Here I only show two days. The same pattern holds for the other days. 
</p>
<div class="org-src-container">
<pre class="src src-ipython">grouped_mean = Train.groupby(['weekday', 'hour']).agg({
    'total_onshift_dashers':
    np.sum,
    'total_busy_dashers':
    np.sum,
    'total_outstanding_orders':
    np.sum
})


# define a function to make a plot for the market features of each hour
# create plot
def f_plot(which_day=0, day='Monday'):
    fig, ax = plt.subplots()
    index = np.arange(grouped_mean.loc[which_day].shape[0])
    bar_width = .25
    opacity = 0.8

    rects1 = plt.bar(
        index,
        grouped_mean.loc[which_day].total_busy_dashers,
        bar_width,
        alpha=opacity,
        color='b',
        label='# busy_dashers')

    rects2 = plt.bar(
        index + bar_width,
        grouped_mean.loc[which_day].total_onshift_dashers,
        bar_width,
        alpha=opacity,
        color='g',
        label='# onshift_dashers')

    rects3 = plt.bar(
        index + 2 * bar_width,
        grouped_mean.loc[which_day].total_outstanding_orders,
        bar_width,
        alpha=opacity,
        color='r',
        label='# outstanding_orders')

    plt.xlabel('Day of Week')
    plt.ylabel('Market Features')
    plt.title('Market Features by hour on ' + day)
    plt.xticks(index + bar_width, grouped_mean.loc[which_day].index.values)
    plt.legend()


f_plot(1, 'Monday')
</pre>
</div>


<div class="figure">
<p><img src="./obipy-resources/57942kdl.png" alt="57942kdl.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">f_plot(6, 'Saturday')
</pre>
</div>


<div class="figure">
<p><img src="./obipy-resources/57942xnr.png" alt="57942xnr.png" />
</p>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgd812eda" class="outline-4">
<h4 id="orgd812eda"><span class="section-number-4">2.1.3</span> Hour of day</h4>
<div class="outline-text-4" id="text-2-1-3">
<p>
Hour of day is an ordinal cyclic variables. It is inappropriate to treat this variable as numeric or ordinal. We need to take care of cyclicity. Thus we do the following trigonometric transformation
</p>

\begin{eqnarray*}
x &=& \sin(2\pi\cdot hour/24)\\
y &=& \cos(2\pi\cdot hour/24)
\end{eqnarray*}

<p>
After the transformation, the distance between 1am and 24:00 and the distance between 1am and 2am are the same. Hence, we replace the variable <code>hour</code> by <code>x-hour</code> and <code>y-hour</code>. 
</p>

<div class="org-src-container">
<pre class="src src-ipython">def hour_x(hour):
    return math.sin(2 * math.pi * hour / 24)


def hour_y(hour):
    return math.cos(2 * math.pi * hour / 24)


Train['hour_x'] = Train.hour.map(hour_x)
Train['hour_y'] = Train.hour.map(hour_y)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org88e72b8" class="outline-3">
<h3 id="org88e72b8"><span class="section-number-3">2.2</span> Missing values</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-orgaed3c97" class="outline-4">
<h4 id="orgaed3c97"><span class="section-number-4">2.2.1</span> Count the number of missing values for each column</h4>
<div class="outline-text-4" id="text-2-2-1">
<div class="org-src-container">
<pre class="src src-ipython">Train.isnull().sum()
</pre>
</div>

<pre class="example">
market_id                                         987
created_at                                          0
actual_delivery_time                                7
store_id                                            0
store_primary_category                           4760
order_protocol                                    995
total_items                                         0
subtotal                                            0
num_distinct_items                                  0
min_item_price                                      0
max_item_price                                      0
total_onshift_dashers                           16262
total_busy_dashers                              16262
total_outstanding_orders                        16262
estimated_order_place_duration                      0
estimated_store_to_consumer_driving_duration      526
weekday                                             0
hour                                                0
hour_x                                              0
hour_y                                              0
dtype: int64
</pre>
</div>
</div>

<div id="outline-container-org5564508" class="outline-4">
<h4 id="org5564508"><span class="section-number-4">2.2.2</span> Impute the missing values for some columns</h4>
<div class="outline-text-4" id="text-2-2-2">
</div>
<ol class="org-ol">
<li><a id="org0d987fa"></a>For <code>total_onshift_dashers</code>, <code>total_busy_dashers</code>, and <code>total_outstanding_orders</code>, replace the missing values by the corresponding average from the same hour of day and the same day of week<br />
<div class="outline-text-5" id="text-2-2-2-1">
<div class="org-src-container">
<pre class="src src-ipython">cols = [
    'total_onshift_dashers',
    'total_busy_dashers',
    'total_outstanding_orders'
]

grouped_mean = Train.groupby(['weekday', 'hour']).agg({
    'total_onshift_dashers':
    np.mean,
    'total_busy_dashers':
    np.mean,
    'total_outstanding_orders':
    np.mean
})
Train_merge = Train.reset_index().join(
    grouped_mean, on=['weekday', 'hour'], lsuffix='_x', rsuffix='_y')

Train.loc[Train.loc[:,cols].isnull().any(axis=1).tolist(), cols] =\
    Train_merge.loc[Train.loc[:, cols].isnull().any(axis=1).tolist(),
                    [c+'_y' for c in cols]].values
</pre>
</div>
</div>
</li>

<li><a id="org862bb32"></a>For <code>estimated_store_to_consumer_driving_duration</code>, replace the missing values by the average from the same store<br />
<div class="outline-text-5" id="text-2-2-2-2">
<div class="org-src-container">
<pre class="src src-ipython">grouped_mean_store = Train.groupby('store_id').agg({
    'estimated_store_to_consumer_driving_duration':
    np.mean
})

Train_merge_store = Train.reset_index().join(
    grouped_mean_store, on='store_id', lsuffix='_x', rsuffix='_y')
Train.loc[Train.loc[:,'estimated_store_to_consumer_driving_duration']\
    .isnull().tolist(), 'estimated_store_to_consumer_driving_duration'] =\
    Train_merge_store.loc[Train.loc[:,
    'estimated_store_to_consumer_driving_duration'].isnull().tolist(),
    'estimated_store_to_consumer_driving_duration'+'_y']

# remove the only data point that has NaN for
# estimated_store_to_consumer_driving_duration. Note, this store only has this
# one record
Train = Train[~Train.estimated_store_to_consumer_driving_duration.isnull()]
</pre>
</div>
</div>
</li>

<li><a id="orge198f5d"></a>Use the majority of the <code>store_primary_category</code> of a store to replace the missing values<br />
<div class="outline-text-5" id="text-2-2-2-3">
<div class="org-src-container">
<pre class="src src-ipython">Train.isnull().sum()

group_maj_categ = Train.groupby('store_id').\
            agg({'store_primary_category':
                lambda x: np.nan if len(pd.value_counts(x)) == 0
                else pd.value_counts(x).idxmax()})

Train_merge_store = Train.reset_index().join(
    group_maj_categ, on='store_id', lsuffix='_x', rsuffix='_y')

Train.isnull().sum()
Train_merge_store.isnull().sum()
Train.loc[Train.loc[:,'store_primary_category']\
            .isnull().tolist(), 'store_primary_category'] =\
            Train_merge_store.loc[Train.loc[:,
            'store_primary_category'].isnull().tolist(),
                                  'store_primary_category_y']
</pre>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-org9021131" class="outline-4">
<h4 id="org9021131"><span class="section-number-4">2.2.3</span> Treat the <code>NaN</code> as an extra level of the categorical variable</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
For the <code>NaN's</code> in <code>market_id</code> and <code>order_protocol</code>, and the remaining <code>NaN's</code> in <code>store_primary_category_x</code>, I treat them as a special level of these categorical variables 
</p>
</div>
</div>
<div id="outline-container-orgb4e7003" class="outline-4">
<h4 id="orgb4e7003"><span class="section-number-4">2.2.4</span> Remove some data points</h4>
<div class="outline-text-4" id="text-2-2-4">
</div>
<ol class="org-ol">
<li><a id="orgbc4b79a"></a>remove rows with no delivery time<br />
<div class="outline-text-5" id="text-2-2-4-1">
<p>
Since no label is recorded, nothing can be learned from the data points. I remove those data points.
</p>
<div class="org-src-container">
<pre class="src src-ipython">Train = Train[~Train.actual_delivery_time.isnull()]
</pre>
</div>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org4b51796" class="outline-3">
<h3 id="org4b51796"><span class="section-number-3">2.3</span> Compute the duration from orders created to orders delivered</h3>
<div class="outline-text-3" id="text-2-3">
<div class="org-src-container">
<pre class="src src-ipython">Train['duration'] = (Train['actual_delivery_time'] -
                     Train['created_at']).map(lambda x: x.seconds)
Train.drop(
    ['actual_delivery_time', 'created_at', 'hour'], axis=1, inplace=True)
Train.to_csv('./data/data.csv', index=False)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org608c609" class="outline-2">
<h2 id="org608c609"><span class="section-number-2">3</span> Training</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org5ca7a10" class="outline-3">
<h3 id="org5ca7a10"><span class="section-number-3">3.1</span> Automatic Machine Learnig (AutoML)</h3>
<div class="outline-text-3" id="text-3-1">
<p>
In recent years a number of AutoML have been developed. <a href="https://h2o-release.s3.amazonaws.com/h2o/master/3888/docs-website/h2o-docs/automl.html">H2O</a> offers an easy-to-use AutoML package. The AutoML tools significantly reduce the effort on model implementation when exploring different models. Data scientist just need to specify the models to be included, and then these models will be automatically tuned and evaluated. Keep in mind, AutoML is suitable for the initial model exploration but not for getting the best performing model. Once an appropriate model family is identified, further tuning is still required.   
</p>
<div class="org-src-container">
<pre class="src src-ipython">import h2o
from h2o.automl import H2OAutoML

train = pd.read_csv('./data/data.csv')
train.market_id = train.market_id.astype("str")
train.order_protocol = train.order_protocol.astype("str")

h2o.init()
train = h2o.H2OFrame(train)
x = train.columns
x.remove('actual_delivery_time')
x.remove('created_at')
y = 'duration'
x.remove(y)

# Run AutoML for 30 seconds
aml = H2OAutoML(max_runtime_secs=30)
aml.train(x=x, y=y, training_frame=train)
# View the AutoML Leaderboard
lb = aml.leaderboard
</pre>
</div>

<ul class="org-ul">
<li>Model comparison</li>
</ul>

<p>
As indicated by the following table, the best performing model is an ensemble model. This is a stacked ensemble model. Its algorithm can be found <a href="https://www.degruyter.com/view/j/sagmb.2007.6.issue-1/sagmb.2007.6.1.1309/sagmb.2007.6.1.1309.xml">here</a>. In short, stacked ensemble learning is a class of algorithms that involves training a second-level “metalearner” to find the optimal combination of the base learners. Unlike bagging and boosting, the goal in stacking is to ensemble strong, diverse sets of learners together.
I will use <code>StackedEnsemble_BestOfFamily</code> as the model for servnig. 
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">model<sub>id</sub></th>
<th scope="col" class="org-right">mean<sub>residual</sub><sub>deviance</sub></th>
<th scope="col" class="org-right">rmse</th>
<th scope="col" class="org-right">mae</th>
<th scope="col" class="org-right">rmsle</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">StackedEnsemble<sub>AllModels</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub></td>
<td class="org-right">948309</td>
<td class="org-right">973.812</td>
<td class="org-right">625.31</td>
<td class="org-right">0.281234</td>
</tr>

<tr>
<td class="org-left">StackedEnsemble<sub>BestOfFamily</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub></td>
<td class="org-right">954067</td>
<td class="org-right">976.764</td>
<td class="org-right">626.901</td>
<td class="org-right">0.281996</td>
</tr>

<tr>
<td class="org-left">GBM<sub>grid</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub><sub>model</sub><sub>4</sub></td>
<td class="org-right">973542</td>
<td class="org-right">986.682</td>
<td class="org-right">636.629</td>
<td class="org-right">0.286368</td>
</tr>

<tr>
<td class="org-left">GBM<sub>grid</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub><sub>model</sub><sub>2</sub></td>
<td class="org-right">981859</td>
<td class="org-right">990.888</td>
<td class="org-right">641.478</td>
<td class="org-right">0.288185</td>
</tr>

<tr>
<td class="org-left">GBM<sub>grid</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub><sub>model</sub><sub>1</sub></td>
<td class="org-right">982456</td>
<td class="org-right">991.189</td>
<td class="org-right">641.57</td>
<td class="org-right">0.288078</td>
</tr>

<tr>
<td class="org-left">GBM<sub>grid</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub><sub>model</sub><sub>3</sub></td>
<td class="org-right">982967</td>
<td class="org-right">991.447</td>
<td class="org-right">641.205</td>
<td class="org-right">0.288238</td>
</tr>

<tr>
<td class="org-left">DeepLearning<sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub></td>
<td class="org-right">987368</td>
<td class="org-right">993.664</td>
<td class="org-right">640.402</td>
<td class="org-right">0.28797</td>
</tr>

<tr>
<td class="org-left">GBM<sub>grid</sub><sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub><sub>model</sub><sub>0</sub></td>
<td class="org-right">990865</td>
<td class="org-right">995.422</td>
<td class="org-right">646.579</td>
<td class="org-right">0.290066</td>
</tr>

<tr>
<td class="org-left">DRF<sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub></td>
<td class="org-right">1.05269e+06</td>
<td class="org-right">1026.01</td>
<td class="org-right">674.232</td>
<td class="org-right">0.302125</td>
</tr>

<tr>
<td class="org-left">XRT<sub>0</sub><sub>AutoML</sub><sub>20180731</sub><sub>024402</sub></td>
<td class="org-right">1.06259e+06</td>
<td class="org-right">1030.82</td>
<td class="org-right">679.858</td>
<td class="org-right">0.304129</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-org">
</pre>
</div>
</div>
</div>

<div id="outline-container-orgc1bfa1c" class="outline-3">
<h3 id="orgc1bfa1c"><span class="section-number-3">3.2</span> Mixed effects model</h3>
<div class="outline-text-3" id="text-3-2">
<p>
A generalized mixed effects model (GLMM) is represented as:
</p>

\begin{equation*}
g(\mu_{ij}) = x_{ij} \beta + z_{ij}b_i
\end{equation*} 
<p>
where g(·) is a monotonic “link” function, x<sub>ij</sub> is 1 × p, and z<sub>ij</sub> is 1 × q, with β a p × 1 vector of fixed effects and b<sub>i</sub> a q × 1 v ector of random effects
</p>

<p>
If we were to apply conventional GLMM, we would need to transform a vector of p
raw covariates X = (X<sub>1</sub>, &#x2026;, X<sub>p</sub>)<sup>T</sup> in the following way
</p>

\begin{equation*}
  φ(X) = (φ_1(X), ..., φ_m(X))
\end{equation*}

<p>
Usually in conventional GLMM, \(φ_j (X)\) are chosen <i>a priori</i> in some way. But here we are concerned with learning an appropriate \(φ_j (X)\) from data. If a deep multi-layer perceptron is used for transforming the covariates, then Z has the form
</p>


\begin{equation*}
f_L(W_L,f_{L-1}(W_{L-1},\cdots,f_1(W_1,X)\cdots))
\end{equation*}
<p>
which is often graphically represented by a network as in the following figure
</p>

<p width="75%" height="75%">
<img src="./Figures/neural-net.png" alt="neural-net.png" width="75%" height="75%" />
 \(L\) is the number of hidden layers in the network, \(w=(W_1,...,W_L)\) is the set of weights
</p>
<div class="org-src-container">
<pre class="src src-ipython">import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from keras import backend as K
from keras.layers import Dense, Input
from keras.regularizers import l2
from mpl_toolkits.mplot3d import Axes3D
from sklearn.preprocessing import scale

import edward as ed
from edward.models import Normal


def neural_network(fixed_effects, lamd=.1, input_dim=None):
    dense = Dense(
        5, activation='tanh', kernel_regularizer=l2(lamd))(fixed_effects)
    output = Dense(
        1, activation='linear', name='output',
        kernel_regularizer=l2(lamd))(dense)
    return K.squeeze(output, axis=1)


sess = ed.get_session()
K.set_session(sess)

INIT_OP = tf.global_variables_initializer()

data = pd.read_csv('~/Dropbox/Quantiply/playground/data.csv')

fixed_effect_predictors = [
    'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',
    'max_item_price', 'total_onshift_dashers', 'total_busy_dashers',
    'total_outstanding_orders', 'estimated_order_place_duration',
    'estimated_store_to_consumer_driving_duration', 'hour_x', 'hour_y'
]

zip_codes = data['market_id'].astype('category').cat.codes + 1

# zip_codes.value_counts()
train_index = data.sample(frac=0.7).index
val_index = data.drop(train_index).index

X = data.drop('duration', axis=1)[fixed_effect_predictors]
X = scale(X)
y = data['duration'].values
X_train = X[train_index]
y_train = y[train_index]
X_val = X[val_index]
y_val = y[val_index]

N, D = X_train.shape

# fixed-effects placeholders
fixed_effects = tf.placeholder(tf.float32, [N, D])

# fixed-effects parameters
b_fixed_effects = Normal(loc=tf.zeros(D), scale=tf.ones(D))
a = Normal(loc=tf.zeros(1), scale=tf.ones(1))

# approximate fixed-effects distributions
qb_fixed_effects = Normal(
    loc=tf.Variable(tf.random_normal([D])),
    scale=tf.nn.softplus(tf.Variable(tf.random_normal([D]))))
qa = Normal(
    loc=tf.Variable(tf.random_normal([1])),
    scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))

n_zip_codes = len(set(zip_codes))

# random-effect placeholder
zip_codes_ph = tf.placeholder(tf.int32, [N])

# random-effect parameter
sigm_zip_code = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))
a_zip_code = Normal(
    loc=tf.zeros(n_zip_codes), scale=sigm_zip_code * tf.ones(n_zip_codes))

# approximate random-effect distribution
qa_zip_code = Normal(
    loc=tf.Variable(tf.random_normal([n_zip_codes])),
    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_zip_codes]))))

a_random_effects = tf.gather(a_zip_code, zip_codes_ph)
# ### Infer parameters

# model
fixed_effects = tf.placeholder(tf.float32, [N, D])
mu_y = a + a_random_effects + neural_network(fixed_effects)
y = Normal(loc=mu_y, scale=tf.ones(N))
latent_vars = {
    b_fixed_effects: qb_fixed_effects,
    a: qa,
    a_zip_code: qa_zip_code
}

# Inference
sess.run(INIT_OP)
inference = ed.KLqp(
    latent_vars,
    data={
        fixed_effects: X_train,
        zip_codes_ph: zip_codes[train_index],
        y: y_train
    })
optimizer = tf.train.RMSPropOptimizer(0.01, epsilon=1.0)
inference.initialize(optimizer=optimizer)
inference.run(n_samples=5, n_iter=1000)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org2923cea" class="outline-2">
<h2 id="org2923cea"><span class="section-number-2">4</span> Prediction</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org9d349d5" class="outline-3">
<h3 id="org9d349d5"><span class="section-number-3">4.1</span> Script for model serving</h3>
<div class="outline-text-3" id="text-4-1">
<p>
For the neural network based mixed effects model, since it is implemented in tensorflow, it can be served via tf.serving. A few advantages of tf.serving are:
</p>

<ul class="org-ul">
<li>Scales to massive data.</li>
<li>Supports online learning.</li>
<li>Supports batch training.</li>
</ul>

<p>
The script I will use for model serving is shown below. If I had more time, I would have built a <a href="https://www.docker.com/">docker</a> container for portability.
</p>
<div class="org-src-container">
<pre class="src src-ipython">import argparse
import math
import os

import h2o
import pandas as pd

parser = argparse.ArgumentParser()
parser.add_argument("--input_path", default=None)
parser.add_argument("--model_path", default=None)
parser.add_argument("--output_path", default=None)
ms = parser.parse_args()


if ms.input_path is None:
    raise ValueError('Please provide the path of your input data.')

if ms.model_path is None:
    raise ValueError('Please provide the path of the model file.')

if ms.output_path is None:
    raise ValueError('Please provide the path to save the results.')

if os.path.isdir(ms.input_path):
    raise IOError('Provided input path is a directory. \
Please provide the path to the data file.')

if os.path.isdir(ms.model_path):
    raise IOError('Provided model path is a directory. \
Please provide the path to the model file.')

if os.path.isdir(ms.output_path):
    raise IOError('Provided output path is a directory.\
Please specify the file path to store the results.')

# Initialize h2o
h2o.init()

# define functions to engineer the feature hour
def hour_x(hour):
    return math.sin(2 * math.pi * hour / 24)

def hour_y(hour):
    return math.cos(2 * math.pi * hour / 24)

def prepare_test_data(input_path=ms.input_path):
    '''Prepare the test dataset

    Parameters
    ----------
    input_path: str
        Path to the saved input data.

    Returns
    -------
    test: H2O.DataFrame
        Test dataset after the same feature engineering. 
    '''
# jason_path = '../../Data Science/data_to_predict.json'
# test = pd.read_json(jason_path, lines = True)
    test = pd.read_json(input_path, lines=True)
    print 'Using input data from %s' % input_path
    # Engineer the features of test data accordingly
    test.created_at = pd.to_datetime(test.created_at)
    test['weekday'] = test.created_at.map(lambda x: x.weekday())
    test['hour'] = test.created_at.map(lambda x: x.hour)
    test['hour_x'] = test.hour.map(hour_x)
    test['hour_y'] = test.hour.map(hour_y)
    test = h2o.H2OFrame(test)
    return test

def predict(model_path=ms.model_path,
            output_path=ms.output_path):
    '''Make predictions

    Parameters
    ----------
    model_path: str
        Path to the saved model file.
    output_path: str
        Path to save the results.

    Returns
    -------
    None
    '''
    # load the saved model
    aml_top = h2o.load_model(model_path)
    # make predictions
    test = prepare_test_data()
    pred = aml_top.predict(test)
    res = pd.DataFrame()
    res['delivery_id'] = test.as_data_frame()['delivery_id']
    res['predicted_delivery_seconds'] = pred.as_data_frame()['predict']
    res.to_csv(output_path, sep='\t', index=False)

if __name__ == "__main__":
    predict()
    h2o.cluster().shutdown()
    print 'Saving results to %s' % ms.output_path
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Qike Max Li</p>
<p class="date">Created: 2018-09-17 Mon 22:56</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
